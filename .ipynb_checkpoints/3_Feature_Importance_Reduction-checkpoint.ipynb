{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_package_loading.py # Code loads data as well as packages that are relevant across most project phases\n",
    "%matplotlib inline\n",
    "\n",
    "uci_features = ['28',  '48',  '64', '105', '128', '153', '241', '281', '318', '336', \n",
    "                '338', '378', '433', '442', '451', '453', '455', '472', '475', '493']\n",
    "\n",
    "madelon_features = ['feat_257', 'feat_269', 'feat_308', 'feat_315', 'feat_336',\n",
    "                   'feat_341', 'feat_395', 'feat_504', 'feat_526', 'feat_639',\n",
    "                   'feat_681', 'feat_701', 'feat_724', 'feat_736', 'feat_769',\n",
    "                   'feat_808', 'feat_829', 'feat_867', 'feat_920', 'feat_956']\n",
    "\n",
    "Xuci_1 = Xuci_1[uci_features]\n",
    "Xuci_2 = Xuci_2[uci_features]\n",
    "Xuci_3 = Xuci_3[uci_features]\n",
    "\n",
    "Xdb_1 = Xdb_1[madelon_features]\n",
    "Xdb_2 = Xdb_2[madelon_features]\n",
    "Xdb_3 = Xdb_3[madelon_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -y psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, RFECV \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying SelectKBest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skb_features(X, y, k=5):\n",
    "    skb = SelectKBest(k=k)\n",
    "    skb.fit(X, y)\n",
    "    \n",
    "    ps = list(skb.pvalues_)\n",
    "    features = skb.get_support()\n",
    "    \n",
    "    return ps, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xuci_1_pvals, Xuci_1_kfeatures = skb_features(Xuci_1, yuci_1)\n",
    "Xuci_2_pvals, Xuci_2_kfeatures = skb_features(Xuci_2, yuci_2)\n",
    "Xuci_3_pvals, Xuci_3_kfeatures = skb_features(Xuci_3, yuci_3)\n",
    "\n",
    "Xdb_1_pvals, Xdb_1_kfeatures = skb_features(Xdb_1, ydb_1)\n",
    "Xdb_2_pvals, Xdb_2_kfeatures = skb_features(Xdb_2, ydb_2)\n",
    "Xdb_3_pvals, Xdb_3_kfeatures = skb_features(Xdb_3, ydb_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['64', '128', '241', '336', '475'], dtype='object')\n",
      "Index(['241', '338', '442', '472', '475'], dtype='object')\n",
      "Index(['28', '64', '241', '336', '475'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xuci_1.columns[Xuci_1_kfeatures])\n",
    "print(Xuci_2.columns[Xuci_2_kfeatures])\n",
    "print(Xuci_3.columns[Xuci_3_kfeatures])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar but not identical results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feat_269', 'feat_341', 'feat_681', 'feat_769', 'feat_920'], dtype='object')\n",
      "Index(['feat_269', 'feat_341', 'feat_681', 'feat_769', 'feat_920'], dtype='object')\n",
      "Index(['feat_269', 'feat_341', 'feat_681', 'feat_701', 'feat_920'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xdb_1.columns[Xdb_1_kfeatures])\n",
    "print(Xdb_2.columns[Xdb_2_kfeatures])\n",
    "print(Xdb_3.columns[Xdb_3_kfeatures])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKB isn't returning consitent matches, but what if we bootstrap each sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_skb(X, y, k=5, boots=20):\n",
    "    np.random.seed(42) # set that seed\n",
    "    size = len(X) #DecisionTreeClassifier// 2 # number of cases to include in each bootstrap sample\n",
    "    \n",
    "    pvals = [] # store list of lists for pvals \n",
    "    votes = [] # store list of lists for votes \n",
    "    \n",
    "    for i in range(boots):\n",
    "        boot_index = np.random.choice(X.index.tolist(), size = size, replace=True)\n",
    "        \n",
    "        X_bs = X.iloc[boot_index, :]\n",
    "        y_bs = y[boot_index]\n",
    "                \n",
    "        ps, features = skb_features(X_bs, y_bs, k=k)\n",
    "                \n",
    "        pvals.append(ps)\n",
    "        votes.append(features)\n",
    "            \n",
    "    pvals_df = pd.DataFrame(pvals, columns = X.columns)\n",
    "    votes_df = pd.DataFrame(votes, columns = X.columns)\n",
    "    \n",
    "    mean_pvals = pvals_df.mean()\n",
    "    sum_votes = votes_df.sum()\n",
    "    \n",
    "    return mean_pvals, sum_votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xuci_1_pvals, Xuci_1_kfeatures = boot_skb(Xuci_1, yuci_1, boots = 1000)\n",
    "Xuci_2_pvals, Xuci_2_kfeatures = boot_skb(Xuci_2, yuci_2, boots = 1000)\n",
    "Xuci_3_pvals, Xuci_3_kfeatures = boot_skb(Xuci_3, yuci_3, boots = 1000)\n",
    "\n",
    "Xdb_1_pvals, Xdb_1_kfeatures = boot_skb(Xdb_1, ydb_1, boots = 1000)\n",
    "Xdb_2_pvals, Xdb_2_kfeatures = boot_skb(Xdb_2, ydb_2, boots = 1000)\n",
    "Xdb_3_pvals, Xdb_3_kfeatures = boot_skb(Xdb_3, ydb_3, boots = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'336', '128', '475', '64', '241'}\n",
      "{'472', '338', '475', '442', '241'}\n",
      "{'28', '336', '475', '64', '241'}\n"
     ]
    }
   ],
   "source": [
    "print(set(Xuci_1_kfeatures.sort_values(ascending=False)[:5].index))\n",
    "print(set(Xuci_2_kfeatures.sort_values(ascending=False)[:5].index))\n",
    "print(set(Xuci_3_kfeatures.sort_values(ascending=False)[:5].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feat_769', 'feat_920', 'feat_341', 'feat_269', 'feat_681'}\n",
      "{'feat_769', 'feat_920', 'feat_341', 'feat_269', 'feat_681'}\n",
      "{'feat_920', 'feat_341', 'feat_701', 'feat_269', 'feat_681'}\n"
     ]
    }
   ],
   "source": [
    "print(set(Xdb_1_kfeatures.sort_values(ascending=False)[:5].index))\n",
    "print(set(Xdb_2_kfeatures.sort_values(ascending=False)[:5].index))\n",
    "print(set(Xdb_3_kfeatures.sort_values(ascending=False)[:5].index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither set of samples are returning consistent sets of features when using 10000 bootstrap samples! Before moving on, let's check the top 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xuci_1_pvals, Xuci_1_kfeatures = boot_skb(Xuci_1, yuci_1, k=10, boots = 1000)\n",
    "Xuci_2_pvals, Xuci_2_kfeatures = boot_skb(Xuci_2, yuci_2, k=10, boots = 1000)\n",
    "Xuci_3_pvals, Xuci_3_kfeatures = boot_skb(Xuci_3, yuci_3, k=10, boots = 1000)\n",
    "\n",
    "Xdb_1_pvals, Xdb_1_kfeatures = boot_skb(Xdb_1, ydb_1, k=10, boots = 1000)\n",
    "Xdb_2_pvals, Xdb_2_kfeatures = boot_skb(Xdb_2, ydb_2, k=10, boots = 1000)\n",
    "Xdb_3_pvals, Xdb_3_kfeatures = boot_skb(Xdb_3, ydb_3, k=10, boots = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['105', '128', '153', '241', '336', '338', '378', '475', '48', '64'], dtype='object')\n",
      "Index(['128', '241', '336', '338', '442', '453', '472', '475', '493', '64'], dtype='object')\n",
      "Index(['241', '28', '318', '336', '451', '453', '475', '48', '493', '64'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xuci_1_kfeatures.sort_values(ascending=False)[:10].index.sort_values())\n",
    "print(Xuci_2_kfeatures.sort_values(ascending=False)[:10].index.sort_values())\n",
    "print(Xuci_3_kfeatures.sort_values(ascending=False)[:10].index.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feat_269', 'feat_336', 'feat_341', 'feat_681', 'feat_701', 'feat_736',\n",
      "       'feat_769', 'feat_808', 'feat_829', 'feat_920'],\n",
      "      dtype='object')\n",
      "Index(['feat_269', 'feat_315', 'feat_336', 'feat_341', 'feat_681', 'feat_701',\n",
      "       'feat_769', 'feat_808', 'feat_829', 'feat_920'],\n",
      "      dtype='object')\n",
      "Index(['feat_269', 'feat_315', 'feat_341', 'feat_681', 'feat_701', 'feat_736',\n",
      "       'feat_769', 'feat_808', 'feat_829', 'feat_920'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(Xdb_1_kfeatures.sort_values(ascending=False)[:10].index.sort_values())\n",
    "print(Xdb_2_kfeatures.sort_values(ascending=False)[:10].index.sort_values())\n",
    "print(Xdb_3_kfeatures.sort_values(ascending=False)[:10].index.sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rfe(X, y, estimator = DecisionTreeClassifier(max_depth=10)):\n",
    "    rfe = RFE(estimator = estimator, n_features_to_select=5)\n",
    "    rfe.fit(X, y)\n",
    "    \n",
    "    return X.columns[rfe.get_support()]\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['105', '153', '241', '442', '493'], dtype='object')\n",
      "Index(['48', '105', '153', '338', '475'], dtype='object')\n",
      "Index(['48', '153', '318', '338', '493'], dtype='object')\n",
      "Index(['feat_257', 'feat_269', 'feat_341', 'feat_808', 'feat_920'], dtype='object')\n",
      "Index(['feat_269', 'feat_395', 'feat_504', 'feat_769', 'feat_829'], dtype='object')\n",
      "Index(['feat_269', 'feat_308', 'feat_724', 'feat_769', 'feat_829'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "get_rfe(Xuci_1, yuci_1)\n",
    "get_rfe(Xuci_2, yuci_2)\n",
    "get_rfe(Xuci_3, yuci_3)\n",
    "\n",
    "get_rfe(Xdb.sort_values())_1, ydb_1)\n",
    "get_rfe(Xdb_2, ydb_2)\n",
    "get_rfe(Xdb_3, ydb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['28', '128', '153', '318', '433'], dtype='object')\n",
      "Index(['28', '48', '128', '378', '451'], dtype='object')\n",
      "Index(['28', '48', '128', '281', '378'], dtype='object')\n",
      "Index(['feat_257', 'feat_269', 'feat_308', 'feat_681', 'feat_829'], dtype='object')\n",
      "Index(['feat_257', 'feat_269', 'feat_308', 'feat_681', 'feat_829'], dtype='object')\n",
      "Index(['feat_257', 'feat_269', 'feat_395', 'feat_681', 'feat_829'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "get_rfe(Xuci_1, yuci_1, LogisticRegression())\n",
    "get_rfe(Xuci_2, yuci_2, LogisticRegression())\n",
    "get_rfe(Xuci_3, yuci_3, LogisticRegression())\n",
    "\n",
    "get_rfe(Xdb_1, ydb_1, LogisticRegression())\n",
    "get_rfe(Xdb_2, ydb_2, LogisticRegression())\n",
    "get_rfe(Xdb_3, ydb_3, LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also getting inconsitent results, particularly accross estimators. Let's try bootstrapping here as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boot_rfe(X, y, estimator = DecisionTreeClassifier(max_depth=10), boots=20):\n",
    "    np.random.seed(42) # set that seed\n",
    "    size = len(X) #DecisionTreeClassifier// 2 # number of cases to include in each bootstrap sample\n",
    "    \n",
    "    votes = {} # store list of lists for votes \n",
    "    \n",
    "    for i in range(boots):\n",
    "        boot_index = np.random.choice(X.index.tolist(), size = size, replace=True)\n",
    "        \n",
    "        X_bs = X.iloc[boot_index, :]\n",
    "        y_bs = y[boot_index]\n",
    "                \n",
    "        features = get_rfe(X_bs, y_bs, estimator)\n",
    "                \n",
    "        for fea in features:\n",
    "            if fea in votes.keys():\n",
    "                votes[fea] += 1\n",
    "            else:\n",
    "                votes[fea] = 1\n",
    "        \n",
    "    return votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xuci_1_rfe_features = boot_rfe(Xuci_1, yuci_1, boots = 1000)\n",
    "Xuci_2_rfe_features = boot_rfe(Xuci_2, yuci_2, boots = 1000)\n",
    "Xuci_3_rfe_features = boot_rfe(Xuci_3, yuci_3, boots = 1000)\n",
    "\n",
    "Xdb_1_rfe_features = boot_rfe(Xdb_1, ydb_1, boots = 1000)\n",
    "Xdb_2_rfe_features = boot_rfe(Xdb_2, ydb_2, boots = 1000)\n",
    "Xdb_3_rfe_features = boot_rfe(Xdb_3, ydb_3, boots = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['338', '48', '105', '442', '241'], dtype='object')\n",
      "Index(['338', '48', '475', '105', '241'], dtype='object')\n",
      "Index(['338', '378', '318', '241', '442'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(Xuci_1_rfe_features).sort_values(ascending = False)[:5].index)\n",
    "print(pd.Series(Xuci_2_rfe_features).sort_values(ascending = False)[:5].index)\n",
    "print(pd.Series(Xuci_3_rfe_features).sort_values(ascending = False)[:5].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['feat_269', 'feat_808', 'feat_341', 'feat_829', 'feat_504'], dtype='object')\n",
      "Index(['feat_269', 'feat_808', 'feat_681', 'feat_724', 'feat_395'], dtype='object')\n",
      "Index(['feat_269', 'feat_808', 'feat_724', 'feat_829', 'feat_769'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(Xdb_1_rfe_features).sort_values(ascending = False)[:5].index)\n",
    "print(pd.Series(Xdb_2_rfe_features).sort_values(ascending = False)[:5].index)\n",
    "print(pd.Series(Xdb_3_rfe_features).sort_values(ascending = False)[:5].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blast! Still inconsistent results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at RandomForest's feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_gridsearch(X, y):\n",
    "    rfc_param = {'n_estimators': [10, 50, 100, 500, 1000],\n",
    "                'max_depth': [1, 5, 10, None],\n",
    "                'max_features': ['auto', 'log2', 'sqrt']}\n",
    "\n",
    "    rfc_gs = GridSearchCV(RandomForestClassifier(),\n",
    "                         rfc_param,\n",
    "                         cv=5,\n",
    "                         n_jobs = -1)\n",
    "    \n",
    "    rfc_gs.fit(X, y)\n",
    "    \n",
    "    importance_df = pd.DataFrame(list(zip(X.columns, rfc_gs.best_estimator_.feature_importances_)), \n",
    "                                 columns = ['Feature', 'Importance'])\n",
    "    \n",
    "    return importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci1_rfgs_importance = rfc_gridsearch(Xuci_1, yuci_1)\n",
    "uci2_rfgs_importance = rfc_gridsearch(Xuci_2, yuci_2)\n",
    "uci3_rfgs_importance = rfc_gridsearch(Xuci_3, yuci_3)\n",
    "db1_rfgs_importance = rfc_gridsearch(Xdb_1, ydb_1)\n",
    "db2_rfgs_importance = rfc_gridsearch(Xdb_2, ydb_2)\n",
    "db3_rfgs_importance = rfc_gridsearch(Xdb_3, ydb_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

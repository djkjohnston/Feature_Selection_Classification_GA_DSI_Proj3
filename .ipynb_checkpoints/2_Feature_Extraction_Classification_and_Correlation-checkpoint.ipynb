{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective\n",
    "\n",
    "Try alternate methods to identify related features. The repeated related feature models took a considerable amount of time to run. I want to try some different methods to see if the process can be accelerated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run data_package_loading.py # Code loads data as well as packages that are relevant across most project phases\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Single feature prediction of Target. \n",
    "Will a single feature be a strong predictor of the target? Can we identify the true features as those that are strong predictors of the target?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = [(Xuci_1, yuci_1, 'uci_1'), \n",
    "               (Xuci_2, yuci_2, 'uci_2'), \n",
    "               (Xuci_3, yuci_3, 'uci_3'), \n",
    "               (Xdb_1,  ydb_1, 'db_1'), \n",
    "               (Xdb_2,  ydb_2, 'db_2'), \n",
    "               (Xdb_3,  ydb_3, 'db_3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no need to scale since we are only testing one feature at a time.\n",
    "def feature_test(X, y, classifier):\n",
    "    mean_scores = []\n",
    "#     y = np.array(y).reshape(-1, 1)\n",
    "    \n",
    "    # Run regresspr with Kfold\n",
    "    for col in tqdm(X.columns):\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        \n",
    "        Xcol = X[[col]]\n",
    "        \n",
    "        # Set up Kfolds split\n",
    "        skf = StratifiedKFold(n_splits=10, shuffle=True, random_state = 42)\n",
    "        skf.get_n_splits(Xcol, y)\n",
    "        \n",
    "        for train_cv_index, val_cv_index in skf.split(Xcol, y):\n",
    "            X_train_temp = Xcol.iloc[train_cv_index, :]\n",
    "            y_train_temp = y[train_cv_index]\n",
    "            X_test_temp = Xcol.iloc[val_cv_index, :]\n",
    "            y_test_temp = y[val_cv_index]\n",
    "        \n",
    "            #instantiate and fit\n",
    "            model = classifier\n",
    "            model.fit(X_train_temp, y_train_temp)\n",
    "            \n",
    "            #score\n",
    "            train_scores.append(model.score(X_train_temp, y_train_temp))\n",
    "            test_scores.append(model.score(X_test_temp, y_test_temp))\n",
    "        \n",
    "        #store mean scores for each feature\n",
    "        mean_scores.append({'feature': col,\n",
    "                            'train_score': np.array(train_scores).mean(),\n",
    "                            'test_score': np.array(test_scores).mean()})\n",
    "        \n",
    "    df_scores = pd.DataFrame(mean_scores)\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:22<00:00, 22.01it/s]\n"
     ]
    }
   ],
   "source": [
    "uci_feature_test = feature_test(Xuci_1, yuci_1, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>0.593277</td>\n",
       "      <td>0.610607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>339</td>\n",
       "      <td>0.582363</td>\n",
       "      <td>0.761622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>125</td>\n",
       "      <td>0.579999</td>\n",
       "      <td>0.737384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>0.577457</td>\n",
       "      <td>0.687630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.577404</td>\n",
       "      <td>0.651772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  test_score  train_score\n",
       "86       86    0.593277     0.610607\n",
       "339     339    0.582363     0.761622\n",
       "125     125    0.579999     0.737384\n",
       "176     176    0.577457     0.687630\n",
       "23       23    0.577404     0.651772"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_feature_test.sort_values('test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18,  23,  30,  42,  56,  65,  68,  86, 102, 116, 125, 140, 176,\n",
       "       189, 197, 249, 339, 389, 403, 444])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_feature_test['feature'] = [int(i) for i in uci_feature_test['feature']]\n",
    "top_features = uci_feature_test.sort_values('test_score', ascending=False).head(20)['feature'].values\n",
    "top_features.sort()\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_true_features = np.array([ 28,  48,  64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433, 442, 451, 453, 455, 472, 475, 493])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i in uci_true_features for i in top_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From prior work, I have strong reason to believe that the 'right' features are the following:\n",
    "\n",
    "`array([ 28,  48,  64, 105, 128, 153, 241, 281, 318, 336, 338, 378, 433, 442, 451, 453, 455, 472, 475, 493])`\n",
    "\n",
    "It appears that using we  identify none of the correct features using `DecisionTreeRegressor()` on the `uci_1` data.\n",
    "\n",
    "Let's try to use KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:28<00:00, 17.25it/s]\n"
     ]
    }
   ],
   "source": [
    "uci_feature_test = feature_test(Xuci_1, yuci_1, KNeighborsClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  56,  68,  79, 129, 140, 176, 180, 184, 204, 227, 249, 298,\n",
       "       310, 360, 370, 374, 376, 405, 484])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_feature_test['feature'] = [int(i) for i in uci_feature_test['feature']]\n",
    "top_features = uci_feature_test.sort_values('test_score', ascending=False).head(20)['feature'].values\n",
    "top_features.sort()\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i in uci_true_features for i in top_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No good with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:24<00:00, 20.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 48,  64,  75, 105, 130, 153, 199, 241, 271, 272, 290, 336, 338,\n",
       "       378, 431, 433, 442, 463, 472, 475])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_feature_test = feature_test(Xuci_1, yuci_1, LogisticRegression())\n",
    "uci_feature_test['feature'] = [int(i) for i in uci_feature_test['feature']]\n",
    "top_features = uci_feature_test.sort_values('test_score', ascending=False).head(20)['feature'].values\n",
    "top_features.sort()\n",
    "top_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i in uci_true_features for i in top_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12 features isnt bad. Let's see where the right features are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.513641</td>\n",
       "      <td>0.513636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.554156</td>\n",
       "      <td>0.557064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.575386</td>\n",
       "      <td>0.572988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0.543194</td>\n",
       "      <td>0.544948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>128</td>\n",
       "      <td>0.513641</td>\n",
       "      <td>0.513636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>0.538890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>0.570574</td>\n",
       "      <td>0.576013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>0.522838</td>\n",
       "      <td>0.530801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>318</td>\n",
       "      <td>0.511419</td>\n",
       "      <td>0.513385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>0.577659</td>\n",
       "      <td>0.574754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>0.570889</td>\n",
       "      <td>0.571470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>0.558958</td>\n",
       "      <td>0.551260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>0.538598</td>\n",
       "      <td>0.537620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>442</td>\n",
       "      <td>0.547696</td>\n",
       "      <td>0.549486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>451</td>\n",
       "      <td>0.513641</td>\n",
       "      <td>0.513636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>0.518338</td>\n",
       "      <td>0.519193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>455</td>\n",
       "      <td>0.505216</td>\n",
       "      <td>0.502789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>0.552193</td>\n",
       "      <td>0.560096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.579044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>493</td>\n",
       "      <td>0.518288</td>\n",
       "      <td>0.523730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  test_score  train_score\n",
       "28        28    0.513641     0.513636\n",
       "48        48    0.554156     0.557064\n",
       "64        64    0.575386     0.572988\n",
       "105      105    0.543194     0.544948\n",
       "128      128    0.513641     0.513636\n",
       "153      153    0.533788     0.538890\n",
       "241      241    0.570574     0.576013\n",
       "281      281    0.522838     0.530801\n",
       "318      318    0.511419     0.513385\n",
       "336      336    0.577659     0.574754\n",
       "338      338    0.570889     0.571470\n",
       "378      378    0.558958     0.551260\n",
       "433      433    0.538598     0.537620\n",
       "442      442    0.547696     0.549486\n",
       "451      451    0.513641     0.513636\n",
       "453      453    0.518338     0.519193\n",
       "455      455    0.505216     0.502789\n",
       "472      472    0.552193     0.560096\n",
       "475      475    0.579720     0.579044\n",
       "493      493    0.518288     0.523730"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uci_feature_test[uci_feature_test['feature'].isin(uci_true_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>475</td>\n",
       "      <td>0.579720</td>\n",
       "      <td>0.579044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>336</td>\n",
       "      <td>0.577659</td>\n",
       "      <td>0.574754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>0.575386</td>\n",
       "      <td>0.572988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>338</td>\n",
       "      <td>0.570889</td>\n",
       "      <td>0.571470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>0.570574</td>\n",
       "      <td>0.576013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>0.565673</td>\n",
       "      <td>0.564139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.564131</td>\n",
       "      <td>0.562884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>378</td>\n",
       "      <td>0.558958</td>\n",
       "      <td>0.551260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>0.554156</td>\n",
       "      <td>0.557064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>472</td>\n",
       "      <td>0.552193</td>\n",
       "      <td>0.560096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>271</td>\n",
       "      <td>0.547950</td>\n",
       "      <td>0.545459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>0.547746</td>\n",
       "      <td>0.551008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>442</td>\n",
       "      <td>0.547696</td>\n",
       "      <td>0.549486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>290</td>\n",
       "      <td>0.547436</td>\n",
       "      <td>0.555800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>105</td>\n",
       "      <td>0.543194</td>\n",
       "      <td>0.544948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>75</td>\n",
       "      <td>0.539333</td>\n",
       "      <td>0.549759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>433</td>\n",
       "      <td>0.538598</td>\n",
       "      <td>0.537620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>463</td>\n",
       "      <td>0.535808</td>\n",
       "      <td>0.537866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>431</td>\n",
       "      <td>0.533949</td>\n",
       "      <td>0.541165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>153</td>\n",
       "      <td>0.533788</td>\n",
       "      <td>0.538890</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  test_score  train_score\n",
       "475      475    0.579720     0.579044\n",
       "336      336    0.577659     0.574754\n",
       "64        64    0.575386     0.572988\n",
       "338      338    0.570889     0.571470\n",
       "241      241    0.570574     0.576013\n",
       "272      272    0.565673     0.564139\n",
       "199      199    0.564131     0.562884\n",
       "378      378    0.558958     0.551260\n",
       "48        48    0.554156     0.557064\n",
       "472      472    0.552193     0.560096\n",
       "271      271    0.547950     0.545459\n",
       "130      130    0.547746     0.551008\n",
       "442      442    0.547696     0.549486\n",
       "290      290    0.547436     0.555800\n",
       "105      105    0.543194     0.544948\n",
       "75        75    0.539333     0.549759\n",
       "433      433    0.538598     0.537620\n",
       "463      463    0.535808     0.537866\n",
       "431      431    0.533949     0.541165\n",
       "153      153    0.533788     0.538890"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uci_feature_test.sort_values('test_score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if more data helps by testing with data sourced from the Madelon db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:50<00:00, 19.98it/s]\n"
     ]
    }
   ],
   "source": [
    "db1_feature_test = feature_test(Xdb_1, ydb_1, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['feat_226', 'feat_269', 'feat_336', 'feat_341', 'feat_416',\n",
       "       'feat_443', 'feat_480', 'feat_543', 'feat_559', 'feat_639',\n",
       "       'feat_681', 'feat_701', 'feat_707', 'feat_769', 'feat_778',\n",
       "       'feat_808', 'feat_829', 'feat_873', 'feat_920', 'feat_956'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_db1_features = db1_feature_test.sort_values('test_score', ascending=False).head(20)['feature'].values\n",
    "top_db1_features.sort()\n",
    "top_db1_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'True' Madelon DB predictors:\n",
    "\n",
    "`[257, 269, 308, 315, 336, 341, 395, 504, 526, 639, 681, 701, 724, 736, 769, 808, 829, 867, 920, 956]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Correlations of features. \n",
    "Pandas has a built in `.corr()` method that tests the correlation of features within a matrix. I originally disregarded this approach since parsing the correlation matrix seemed more effort than it was worth. Let's see if I can find a clean way to parse the correlation matrix to identify related features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_test = Xuci_1.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>-0.030589</td>\n",
       "      <td>0.079044</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.045018</td>\n",
       "      <td>-0.022883</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.031829</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>-0.056057</td>\n",
       "      <td>-0.012904</td>\n",
       "      <td>-0.010460</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>-0.055814</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>-0.033592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001863</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.045873</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>-0.086126</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>-0.005845</td>\n",
       "      <td>-0.048256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.101836</td>\n",
       "      <td>-0.027601</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.049305</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.037004</td>\n",
       "      <td>0.060490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030589</td>\n",
       "      <td>-0.045873</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012340</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>0.060894</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>-0.050305</td>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.040547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>0.044949</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.016076</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>-0.014319</td>\n",
       "      <td>0.039001</td>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.088202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079044</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>-0.012340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.064137</td>\n",
       "      <td>-0.011659</td>\n",
       "      <td>-0.070683</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>-0.004106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032361</td>\n",
       "      <td>-0.031768</td>\n",
       "      <td>-0.043497</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.012186</td>\n",
       "      <td>0.041357</td>\n",
       "      <td>-0.061805</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.034481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>-0.049369</td>\n",
       "      <td>0.047841</td>\n",
       "      <td>-0.027970</td>\n",
       "      <td>-0.049692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024900</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>-0.008397</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>-0.021339</td>\n",
       "      <td>-0.067939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.001863 -0.030589  0.079044 -0.016020  0.045018 -0.022883   \n",
       "1  0.001863  1.000000 -0.045873  0.112781  0.072174  0.027823 -0.086126   \n",
       "2 -0.030589 -0.045873  1.000000 -0.012340 -0.050528  0.060894  0.035209   \n",
       "3  0.079044  0.112781 -0.012340  1.000000  0.002612  0.064137 -0.011659   \n",
       "4 -0.016020  0.072174 -0.050528  0.002612  1.000000  0.000710 -0.049369   \n",
       "\n",
       "          7         8         9    ...          490       491       492  \\\n",
       "0  0.002588  0.031829  0.026756    ...     0.013224  0.034647  0.023064   \n",
       "1  0.008964 -0.005845 -0.048256    ...     0.007706 -0.101836 -0.027601   \n",
       "2 -0.050305  0.059404  0.040547    ...     0.012974  0.044949  0.097373   \n",
       "3 -0.070683  0.033268 -0.004106    ...     0.032361 -0.031768 -0.043497   \n",
       "4  0.047841 -0.027970 -0.049692    ...    -0.024900  0.002100  0.002794   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0 -0.056057 -0.012904 -0.010460  0.017305 -0.055814  0.057639 -0.033592  \n",
       "1  0.006410  0.049305  0.022063  0.048790  0.001745 -0.037004  0.060490  \n",
       "2 -0.016076  0.002061 -0.014319  0.039001  0.016703  0.015267  0.088202  \n",
       "3 -0.000271  0.078904  0.012186  0.041357 -0.061805 -0.050831  0.034481  \n",
       "4  0.042962  0.012581 -0.008397  0.042619  0.015844 -0.021339 -0.067939  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>-0.030589</td>\n",
       "      <td>0.079044</td>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.045018</td>\n",
       "      <td>-0.022883</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.031829</td>\n",
       "      <td>0.026756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>0.034647</td>\n",
       "      <td>0.023064</td>\n",
       "      <td>-0.056057</td>\n",
       "      <td>-0.012904</td>\n",
       "      <td>-0.010460</td>\n",
       "      <td>0.017305</td>\n",
       "      <td>-0.055814</td>\n",
       "      <td>0.057639</td>\n",
       "      <td>-0.033592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.045873</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>0.027823</td>\n",
       "      <td>-0.086126</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>-0.005845</td>\n",
       "      <td>-0.048256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007706</td>\n",
       "      <td>-0.101836</td>\n",
       "      <td>-0.027601</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.049305</td>\n",
       "      <td>0.022063</td>\n",
       "      <td>0.048790</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.037004</td>\n",
       "      <td>0.060490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.030589</td>\n",
       "      <td>-0.045873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.012340</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>0.060894</td>\n",
       "      <td>0.035209</td>\n",
       "      <td>-0.050305</td>\n",
       "      <td>0.059404</td>\n",
       "      <td>0.040547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012974</td>\n",
       "      <td>0.044949</td>\n",
       "      <td>0.097373</td>\n",
       "      <td>-0.016076</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>-0.014319</td>\n",
       "      <td>0.039001</td>\n",
       "      <td>0.016703</td>\n",
       "      <td>0.015267</td>\n",
       "      <td>0.088202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.079044</td>\n",
       "      <td>0.112781</td>\n",
       "      <td>-0.012340</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.064137</td>\n",
       "      <td>-0.011659</td>\n",
       "      <td>-0.070683</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>-0.004106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032361</td>\n",
       "      <td>-0.031768</td>\n",
       "      <td>-0.043497</td>\n",
       "      <td>-0.000271</td>\n",
       "      <td>0.078904</td>\n",
       "      <td>0.012186</td>\n",
       "      <td>0.041357</td>\n",
       "      <td>-0.061805</td>\n",
       "      <td>-0.050831</td>\n",
       "      <td>0.034481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.016020</td>\n",
       "      <td>0.072174</td>\n",
       "      <td>-0.050528</td>\n",
       "      <td>0.002612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>-0.049369</td>\n",
       "      <td>0.047841</td>\n",
       "      <td>-0.027970</td>\n",
       "      <td>-0.049692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024900</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.002794</td>\n",
       "      <td>0.042962</td>\n",
       "      <td>0.012581</td>\n",
       "      <td>-0.008397</td>\n",
       "      <td>0.042619</td>\n",
       "      <td>0.015844</td>\n",
       "      <td>-0.021339</td>\n",
       "      <td>-0.067939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.000000  0.001863 -0.030589  0.079044 -0.016020  0.045018 -0.022883   \n",
       "1  0.001863  0.000000 -0.045873  0.112781  0.072174  0.027823 -0.086126   \n",
       "2 -0.030589 -0.045873  0.000000 -0.012340 -0.050528  0.060894  0.035209   \n",
       "3  0.079044  0.112781 -0.012340  0.000000  0.002612  0.064137 -0.011659   \n",
       "4 -0.016020  0.072174 -0.050528  0.002612  0.000000  0.000710 -0.049369   \n",
       "\n",
       "          7         8         9    ...          490       491       492  \\\n",
       "0  0.002588  0.031829  0.026756    ...     0.013224  0.034647  0.023064   \n",
       "1  0.008964 -0.005845 -0.048256    ...     0.007706 -0.101836 -0.027601   \n",
       "2 -0.050305  0.059404  0.040547    ...     0.012974  0.044949  0.097373   \n",
       "3 -0.070683  0.033268 -0.004106    ...     0.032361 -0.031768 -0.043497   \n",
       "4  0.047841 -0.027970 -0.049692    ...    -0.024900  0.002100  0.002794   \n",
       "\n",
       "        493       494       495       496       497       498       499  \n",
       "0 -0.056057 -0.012904 -0.010460  0.017305 -0.055814  0.057639 -0.033592  \n",
       "1  0.006410  0.049305  0.022063  0.048790  0.001745 -0.037004  0.060490  \n",
       "2 -0.016076  0.002061 -0.014319  0.039001  0.016703  0.015267  0.088202  \n",
       "3 -0.000271  0.078904  0.012186  0.041357 -0.061805 -0.050831  0.034481  \n",
       "4  0.042962  0.012581 -0.008397  0.042619  0.015844 -0.021339 -0.067939  \n",
       "\n",
       "[5 rows x 500 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zero at the diagonal.\n",
    "for i in corr_test.columns:\n",
    "    corr_test.loc[i,i] = 0\n",
    "\n",
    "corr_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the absolute value of correlations. We only care about the magnitude, not the direction, of the correlations\n",
    "corr_test = abs(corr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64     0.992330\n",
       "336    0.992330\n",
       "451    0.990578\n",
       "28     0.990578\n",
       "318    0.990541\n",
       "153    0.990379\n",
       "281    0.990379\n",
       "433    0.990082\n",
       "105    0.989993\n",
       "128    0.989993\n",
       "241    0.988937\n",
       "475    0.988937\n",
       "48     0.988595\n",
       "378    0.988595\n",
       "493    0.988309\n",
       "453    0.988309\n",
       "472    0.988133\n",
       "442    0.988133\n",
       "455    0.725369\n",
       "338    0.685807\n",
       "486    0.216672\n",
       "269    0.216672\n",
       "162    0.205203\n",
       "389    0.205203\n",
       "144    0.203834\n",
       "dtype: float64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_test.max().sort_values(ascending=False)[:25]\n",
    "#pretty clear drop in correlations after the 20th "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 48,\n",
       " 64,\n",
       " 105,\n",
       " 128,\n",
       " 153,\n",
       " 241,\n",
       " 281,\n",
       " 318,\n",
       " 336,\n",
       " 338,\n",
       " 378,\n",
       " 433,\n",
       " 442,\n",
       " 451,\n",
       " 453,\n",
       " 455,\n",
       " 472,\n",
       " 475,\n",
       " 493]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = test_corr.max().sort_values(ascending=False)[:20].index\n",
    "best_features = [int(i) for i in best_features]\n",
    "best_features.sort()\n",
    "best_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([i in uci_true_features for i in best_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! This approach is much faster than the iterative model training method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functionalize and run against all datasets.\n",
    "\n",
    "def test_corr(df):\n",
    "    # get the absolute values of correlations\n",
    "    corr_df = abs(df.corr())\n",
    "    \n",
    "    # zero out the diagonal\n",
    "    for i in corr_df.columns:\n",
    "        corr_df.loc[i,i] = 0\n",
    "    \n",
    "    top_features = corr_df.max().sort_values(ascending=False)[:20].index\n",
    "    return np.array(top_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_1_features = test_corr(Xuci_1)\n",
    "uci_2_features = test_corr(Xuci_2)\n",
    "uci_3_features = test_corr(Xuci_3)\n",
    "\n",
    "db_1_features = test_corr(Xdb_1)\n",
    "db_2_features = test_corr(Xdb_2)\n",
    "db_3_features = test_corr(Xdb_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_1_features.sort()\n",
    "uci_2_features.sort()\n",
    "uci_3_features.sort()\n",
    "db_1_features.sort()\n",
    "db_2_features.sort()\n",
    "db_3_features.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_1_features == uci_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uci_2_features == uci_3_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_1_features == db_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['feat_257', 'feat_269', 'feat_308', 'feat_315', 'feat_336',\n",
       "       'feat_341', 'feat_395', 'feat_504', 'feat_526', 'feat_639',\n",
       "       'feat_681', 'feat_701', 'feat_724', 'feat_736', 'feat_769',\n",
       "       'feat_808', 'feat_829', 'feat_867', 'feat_920', 'feat_956'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

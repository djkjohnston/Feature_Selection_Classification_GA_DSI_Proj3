{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Run some naive models (both in terms of feature selection and hyperparameter tuning). This will set benchmark scores that more robustly designed models should outperform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run data_package_loading.py # Code loads data as well as packages that are relevant across most project phases\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# !conda install -y psycopg2\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, RFECV \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "Xdb_1 = pd.read_pickle('data/madelon_db_1')\n",
    "Xdb_2 = pd.read_pickle('data/madelon_db_2')\n",
    "Xdb_3 = pd.read_pickle('data/madelon_db_3')\n",
    "\n",
    "\n",
    "ydb_1 = Xdb_1['target']\n",
    "ydb_2 = Xdb_2['target']\n",
    "ydb_3 = Xdb_3['target']\n",
    "Xdb_1 = Xdb_1.drop(['_id', 'target'], axis=1)\n",
    "Xdb_2 = Xdb_2.drop(['_id', 'target'], axis=1)\n",
    "Xdb_3 = Xdb_3.drop(['_id', 'target'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_target = [(Xuci_1, yuci_1, 'uci_1'), \n",
    "               (Xuci_2, yuci_2, 'uci_2'), \n",
    "               (Xuci_3, yuci_3, 'uci_3'), \n",
    "               (Xdb_1,  ydb_1, 'db_1'), \n",
    "               (Xdb_2,  ydb_2, 'db_2'), \n",
    "               (Xdb_3,  ydb_3, 'db_3')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10 ** 9\n",
    "model_list = [LogisticRegression(C = C), \n",
    "              DecisionTreeClassifier(), \n",
    "              KNeighborsClassifier(n_jobs=-1), \n",
    "              SVC(C = C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipe_cv (X, y, data_name, model):\n",
    "    \n",
    "#     # Test Train split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "    \n",
    "    # Set up Pipeline\n",
    "    pipe = Pipeline([\n",
    "                  ('scaler', StandardScaler()),\n",
    "                  ('model', model)\n",
    "                  ])\n",
    "    \n",
    "    # Set up Kfolds split\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state = 42)\n",
    "    skf.get_n_splits(X, y)\n",
    "    \n",
    "    # Run pipe on Kfold\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for train_cv_index, val_cv_index in skf.split(X, y):\n",
    "        X_train_temp = X.iloc[train_cv_index, :]\n",
    "        y_train_temp = y[train_cv_index]\n",
    "        X_test_temp = X.iloc[val_cv_index, :]\n",
    "        y_test_temp = y[val_cv_index]\n",
    "        \n",
    "        pipe.fit(X_train_temp, y_train_temp)\n",
    "        train_scores.append(pipe.score(X_train_temp, y_train_temp))\n",
    "        test_scores.append(pipe.score(X_test_temp, y_test_temp))\n",
    "\n",
    "    results.append({\n",
    "                'test_train': 'train',\n",
    "                'data': data_name,\n",
    "                'scaler': pipe.named_steps['scaler'],\n",
    "                'model': pipe.named_steps['model'],\n",
    "                'score': np.mean(train_scores) #accuracy for classifications?\n",
    "               })\n",
    "    results.append({\n",
    "            'test_train': 'test',\n",
    "            'data': data_name,\n",
    "            'scaler': pipe.named_steps['scaler'],\n",
    "            'model': pipe.named_steps['model'],\n",
    "            'score': np.mean(test_scores) #accuracy for classifications?\n",
    "           })\n",
    "        \n",
    "    # How do I run the model on the test data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for Xy in data_target:\n",
    "    for model in model_list:\n",
    "        run_pipe_cv(Xy[0], Xy[1], Xy[2], model)\n",
    "        \n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training scores\n",
    "results_df[results_df['test_train'] == 'train'].sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training scores\n",
    "results_df[results_df['test_train'] == 'test'].sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.write_csv('data/benchmark_model_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

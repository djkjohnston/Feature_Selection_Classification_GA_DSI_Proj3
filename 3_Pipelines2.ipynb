{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run data_package_loading.py # Code loads data as well as packages that are relevant across most project phases\n",
    "%matplotlib inline\n",
    "\n",
    "uci_features = ['28',  '48',  '64', '105', '128', '153', '241', '281', '318', '336', \n",
    "                '338', '378', '433', '442', '451', '453', '455', '472', '475', '493']\n",
    "\n",
    "madelon_features = ['feat_257', 'feat_269', 'feat_308', 'feat_315', 'feat_336',\n",
    "                   'feat_341', 'feat_395', 'feat_504', 'feat_526', 'feat_639',\n",
    "                   'feat_681', 'feat_701', 'feat_724', 'feat_736', 'feat_769',\n",
    "                   'feat_808', 'feat_829', 'feat_867', 'feat_920', 'feat_956']\n",
    "\n",
    "Xuci_1 = Xuci_1[uci_features]\n",
    "Xuci_2 = Xuci_2[uci_features]\n",
    "Xuci_3 = Xuci_3[uci_features]\n",
    "\n",
    "# !conda install -y psycopg2\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, RFECV \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "Xdb_1 = pd.read_pickle('data/madelon_db_1')\n",
    "Xdb_2 = pd.read_pickle('data/madelon_db_2')\n",
    "Xdb_3 = pd.read_pickle('data/madelon_db_3')\n",
    "\n",
    "\n",
    "ydb_1 = Xdb_1['target']\n",
    "ydb_2 = Xdb_2['target']\n",
    "ydb_3 = Xdb_3['target']\n",
    "Xdb_1 = Xdb_1[madelon_features]\n",
    "Xdb_2 = Xdb_2[madelon_features]\n",
    "Xdb_3 = Xdb_3[madelon_features]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_reduction(X, y, corr_thresh = 0.7):\n",
    "    \n",
    "    #find order of X features from least important to most important in predicting X\n",
    "    skb = SelectKBest(k=len(X.columns))\n",
    "    skb.fit(X, y)\n",
    "    \n",
    "    tmp_X = X[[col for p,col in sorted(zip(skb.pvalues_,X.columns))]]\n",
    "\n",
    "    # iterate through columns\n",
    "    for col in tmp_X.columns:\n",
    "        corrs = tmp_X.drop(col, axis=1).corrwith(tmp_X[col]) #store the correlations\n",
    "        \n",
    "        # if tested column is too highly correlated, drop it\n",
    "        if max(corrs) > corr_thresh:\n",
    "            tmp_X = tmp_X.drop(col, axis=1)\n",
    "            \n",
    "    return tmp_X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                    ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier(weights='distance'))])\n",
    "\n",
    "rfc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC(probability=True))])\n",
    "\n",
    "# ada_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', AdaBoostClassifier())])\n",
    "\n",
    "# gbc_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "# xgb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_pca_params = {'pca__n_components': [5],\n",
    "                  'classifier__algorithm': ['auto'],\n",
    "                  'classifier__p': [2, 3],\n",
    "             'classifier__n_neighbors': np.linspace(1,10).astype(int)}\n",
    "\n",
    "rfc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__n_estimators': [10, 50, 100, 200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "              'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "# ada_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0]}\n",
    "\n",
    "# gbc_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5],\n",
    "#              'classifier__loss': ['deviance', 'exponential'],\n",
    "#              'classifier__warm_start': [True, False]}\n",
    "\n",
    "# xgb_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 50, 75, 100],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_gs(X, y, pipe, param):\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param, cv=5, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best params:', gs.best_params_)\n",
    "    print('Best fitting score:', gs.best_score_)\n",
    "    print('Train score:', gs.score(X_train, y_train))\n",
    "    print('Test score:', gs.score(X_test, y_test))\n",
    "    \n",
    "    return gs.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xdb_1, ydb_1, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN\n",
      "Best params: {'classifier__algorithm': 'auto', 'classifier__n_neighbors': 8, 'classifier__p': 2, 'pca__n_components': 5}\n",
      "Best fitting score: 0.8327831300949943\n",
      "Train score: 1.0\n",
      "Test score: 0.837510105093\n"
     ]
    }
   ],
   "source": [
    "                  'classifier__oob_score': [True, False],\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying SKB instead of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "rfc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC())])\n",
    "\n",
    "# ada_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', AdaBoostClassifier())])\n",
    "\n",
    "# gbc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "# xgb_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__n_neighbors': np.linspace(1,50).astype(int)}\n",
    "\n",
    "rfc_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__n_estimators': [200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_skb_params = {'skb__k': [5, 10, 15],\n",
    "              'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "# ada_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0]}\n",
    "\n",
    "# gbc_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5],\n",
    "#              'classifier__loss': ['deviance', 'exponential'],\n",
    "#              'classifier__warm_start': [True, False]}\n",
    "\n",
    "# xgb_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 50, 75, 100],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC\n",
      "Best params: {'classifier__C': 1000.0, 'skb__k': 15}\n",
      "Best fitting score: 0.8154685710435896\n",
      "Train score: 0.850434548272\n",
      "Test score: 0.820735650768\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision Tree\")\n",
    "dtc_skb_classifier = test_train_gs(X_train, y_train, dtc_skb_pipe, dtc_skb_params)\n",
    "print(\"\\nLogReg\")\n",
    "lr_skb_classifier = test_train_gs(X_train, y_train, lr_skb_pipe, lr_skb_params)\n",
    "print(\"\\nRandom Forest\")\n",
    "rfc_skb_classifier = test_train_gs(X_train, y_train, rfc_skb_pipe, rfc_skb_params)\n",
    "print(\"\\nKNN\")\n",
    "knn_skb_classifier = test_train_gs(X_train, y_train, knn_skb_pipe, knn_skb_params)\n",
    "print(\"\\nSVC\")\n",
    "svc_skb_classifier = test_train_gs(X_train, y_train, svc_skb_pipe, svc_skb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_pca_classifier = pickle.load(open('classifiers/rfc_classifier', 'rb'))\n",
    "# knn_pca_classifier = pickle.load(open('classifiers/knn_classifier', 'rb'))\n",
    "# svc_pca_classifier = pickle.load(open('classifiers/svc_classifier', 'rb'))\n",
    "# ada_pca_classifier = pickle.load(open('classifiers/ada_classifier', 'rb'))\n",
    "# gbc_pca_classifier = pickle.load(open('classifiers/gbc_classifier', 'rb'))\n",
    "\n",
    "# print(rfc_pca_classifier.score(X_test, y_test))\n",
    "# print(knn_pca_classifier.score(X_test, y_test))\n",
    "# print(svc_pca_classifier.score(X_test, y_test))\n",
    "# print(ada_pca_classifier.score(X_test, y_test))\n",
    "# print(gbc_pca_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_for_skb = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "dtc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                        ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                         ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "rfc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                      ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                         ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_sfm_params = {'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_sfm_params = {'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_sfm_params = {'classifier__n_neighbors': np.linspace(1,50).astype(int)}\n",
    "\n",
    "rfc_sfm_params = {'classifier__n_estimators': [200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_sfm_params = {'classifier__C': np.logspace(-3,3,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC\n",
      "Best params: {'classifier__C': 1000.0}\n",
      "Best fitting score: 0.8160075456444115\n",
      "Train score: 0.849760830021\n",
      "Test score: 0.822352465643\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision Tree\")\n",
    "dtc_sfm_classifier = test_train_gs(X_train, y_train, dtc_sfm_pipe, dtc_sfm_params)\n",
    "print(\"\\nLogReg\")\n",
    "lr_sfm_classifier = test_train_gs(X_train, y_train, lr_sfm_pipe, lr_sfm_params)\n",
    "print(\"\\nRandom Forest\")\n",
    "rfc_sfm_classifier = test_train_gs(X_train, y_train, rfc_sfm_pipe, rfc_sfm_params)\n",
    "print(\"\\nKNN\")\n",
    "knn_sfm_classifier = test_train_gs(X_train, y_train, knn_sfm_pipe, knn_sfm_params)\n",
    "print(\"\\nSVC\")\n",
    "svc_sfm_classifier = test_train_gs(X_train, y_train, svc_sfm_pipe, svc_sfm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see all of the test scores again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Decision Tree: 0.751616814875\n",
      "LogReg: 0.601050929669\n",
      "Random Forest: 0.829830234438\n",
      "KNN: 0.837510105093\n",
      "SVC: 0.831447049313\n",
      "\n",
      "SelectKBest\n",
      "Decision Tree: 0.746564268391\n",
      "LogReg: 0.601455133387\n",
      "Random Forest: 0.825383993533\n",
      "KNN: 0.823767178658\n",
      "SVC: 0.820735650768\n",
      "\n",
      "SelectFromModel\n",
      "Decision Tree: 0.749797898141\n",
      "LogReg: 0.600848827809\n",
      "Random Forest: 0.828011317704\n",
      "KNN: 0.829021827001\n",
      "SVC: 0.822352465643\n"
     ]
    }
   ],
   "source": [
    "print(\"PCA\")\n",
    "print(\"Decision Tree:\", dtc_pca_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_pca_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_pca_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_pca_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_pca_classifier.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nSelectKBest\")\n",
    "print(\"Decision Tree:\", dtc_skb_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_skb_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_skb_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_skb_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_skb_classifier.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nSelectFromModel\")\n",
    "print(\"Decision Tree:\", dtc_sfm_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_sfm_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_sfm_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_sfm_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_sfm_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try voting\n",
    "\n",
    "The PCA models consistently have the strongest accuracy scores. Let's try to see if we can increase the accuracy by ensembling all of the pipelines utilizing PCA. In addition to voting, let's use `GridSearchCV` to determine if weighting the votes will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voting = VotingClassifier(estimators = [('dtc', dtc_pca_classifier), \n",
    "                                        ('lr', lr_pca_classifier),\n",
    "                                        ('rfc', rfc_pca_classifier), \n",
    "                                        ('knn', knn_pca_classifier), \n",
    "                                        ('svc', svc_pca_classifier)],\n",
    "                          voting = 'soft'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       " ('pca',\n",
       "  PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)),\n",
       " ('classifier', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False))]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pca_classifier.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826798706548\n"
     ]
    }
   ],
   "source": [
    "voting.fit(X_train, y_train)\n",
    "print(voting.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "\n",
    "for i in np.linspace(0, 3, 4):\n",
    "    for j in np.linspace(0, 3, 4):\n",
    "        for k in np.linspace(0, 3, 4):\n",
    "            for l in np.linspace(0, 3, 4):\n",
    "                for m in np.linspace(0, 3, 4):\n",
    "                    i = float(i)\n",
    "                    j = float(j)\n",
    "                    k = float(k)\n",
    "                    l = float(l)\n",
    "                    m = float(m)\n",
    "                    \n",
    "                    if (i == 1) & (j == 1) & (k == 1) & (l == 1) & (m == 1):\n",
    "                        weight_list.append([i, j, k, l, m])\n",
    "                    elif (i == j) & (i == k) & (i == l) & (i == m):\n",
    "                        pass\n",
    "                    else:\n",
    "                        weight_list.append([i, j, k, l, m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1021/1021 [1:07:39<00:00,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "vote_weighting_results = []\n",
    "\n",
    "for weights in tqdm(weight_list):\n",
    "    voting.set_params(weights = weights)\n",
    "    vote_weighting_results.append({'weights': weights,\n",
    "                                  'train_score': voting.score(X_train, y_train),\n",
    "                                  'test_score': voting.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_votes = pd.DataFrame(vote_weighting_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.841350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 2.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.841350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.840946</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 3.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.840542</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.840542</td>\n",
       "      <td>0.999528</td>\n",
       "      <td>[1.0, 0.0, 2.0, 2.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.840340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.840340</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.840137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 2.0, 1.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.840137</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 2.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.839935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.839935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0, 2.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 2.0, 3.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 3.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 2.0, 3.0, 3.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 2.0, 3.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0, 3.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>0.997170</td>\n",
       "      <td>[1.0, 0.0, 3.0, 2.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 1.0, 3.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.839733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 1.0, 1.0, 3.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.839531</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[0.0, 0.0, 3.0, 2.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_score  train_score                    weights\n",
       "44     0.841350     1.000000  [0.0, 0.0, 2.0, 3.0, 1.0]\n",
       "88     0.841350     1.000000  [0.0, 1.0, 1.0, 2.0, 1.0]\n",
       "60     0.840946     1.000000  [0.0, 0.0, 3.0, 3.0, 1.0]\n",
       "93     0.840542     1.000000  [0.0, 1.0, 1.0, 3.0, 2.0]\n",
       "297    0.840542     0.999528  [1.0, 0.0, 2.0, 2.0, 2.0]\n",
       "92     0.840340     1.000000  [0.0, 1.0, 1.0, 3.0, 1.0]\n",
       "109    0.840340     1.000000  [0.0, 1.0, 2.0, 3.0, 2.0]\n",
       "156    0.840137     1.000000  [0.0, 2.0, 1.0, 3.0, 1.0]\n",
       "36     0.840137     1.000000  [0.0, 0.0, 2.0, 1.0, 1.0]\n",
       "108    0.839935     1.000000  [0.0, 1.0, 2.0, 3.0, 1.0]\n",
       "23     0.839935     1.000000  [0.0, 0.0, 1.0, 2.0, 0.0]\n",
       "189    0.839733     1.000000  [0.0, 2.0, 3.0, 3.0, 2.0]\n",
       "52     0.839733     1.000000  [0.0, 0.0, 3.0, 1.0, 1.0]\n",
       "190    0.839733     1.000000  [0.0, 2.0, 3.0, 3.0, 3.0]\n",
       "43     0.839733     1.000000  [0.0, 0.0, 2.0, 3.0, 0.0]\n",
       "28     0.839733     1.000000  [0.0, 0.0, 1.0, 3.0, 1.0]\n",
       "314    0.839733     0.997170  [1.0, 0.0, 3.0, 2.0, 3.0]\n",
       "29     0.839733     1.000000  [0.0, 0.0, 1.0, 3.0, 2.0]\n",
       "91     0.839733     1.000000  [0.0, 1.0, 1.0, 3.0, 0.0]\n",
       "56     0.839531     1.000000  [0.0, 0.0, 3.0, 2.0, 1.0]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_votes.sort_values('test_score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best performing model excluded `DecisionTree` and `LogisticRegression`, leaving only `RandomForestClassifier`, `KNeighborsClassifier`, and `SVC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_voting = VotingClassifier(estimators = [\n",
    "                                        ('rfc', rfc_pca_classifier), \n",
    "                                        ('knn', knn_pca_classifier), \n",
    "                                        ('svc', svc_pca_classifier)],\n",
    "                          voting = 'soft'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5 ,  0.75,  1.  ,  1.25,  1.5 ])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linspace(0.5, 1.5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "secondary_weight_list = []\n",
    "\n",
    "for i in np.linspace(0.5, 1.5, 5):\n",
    "    for j in np.linspace(0.5, 1.5, 5):\n",
    "        for k in np.linspace(0.5, 1.5, 5):\n",
    "            i = float(i)\n",
    "            j = float(j)\n",
    "            k = float(k)\n",
    "\n",
    "            if (i == 1) & (j == 1) & (k == 1):\n",
    "                secondary_weight_list.append([i, j, k])\n",
    "            elif (i == j) & (i == k):\n",
    "                pass\n",
    "            else:\n",
    "                secondary_weight_list.append([i, j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(secondary_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rfc', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=Tru...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]))],\n",
       "         n_jobs=1, voting='soft', weights=None)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondary_voting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimators': [('rfc', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', RandomFor...mators=500, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))])), ('knn', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='distance'))])), ('svc', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]))], 'n_jobs': 1, 'voting': 'soft', 'weights': [1.5, 1.5, 1.25], 'rfc': Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', RandomFor...mators=500, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))]), 'knn': Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='distance'))]), 'svc': Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))]), 'rfc__steps': [('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False))], 'rfc__scaler1': StandardScaler(copy=True, with_mean=True, with_std=True), 'rfc__pca': PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'rfc__scaler2': StandardScaler(copy=True, with_mean=True, with_std=True), 'rfc__classifier': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=500, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False), 'rfc__scaler1__copy': True, 'rfc__scaler1__with_mean': True, 'rfc__scaler1__with_std': True, 'rfc__pca__copy': True, 'rfc__pca__iterated_power': 'auto', 'rfc__pca__n_components': 5, 'rfc__pca__random_state': None, 'rfc__pca__svd_solver': 'auto', 'rfc__pca__tol': 0.0, 'rfc__pca__whiten': False, 'rfc__scaler2__copy': True, 'rfc__scaler2__with_mean': True, 'rfc__scaler2__with_std': True, 'rfc__classifier__bootstrap': True, 'rfc__classifier__class_weight': None, 'rfc__classifier__criterion': 'gini', 'rfc__classifier__max_depth': None, 'rfc__classifier__max_features': 'sqrt', 'rfc__classifier__max_leaf_nodes': None, 'rfc__classifier__min_impurity_split': 1e-07, 'rfc__classifier__min_samples_leaf': 1, 'rfc__classifier__min_samples_split': 2, 'rfc__classifier__min_weight_fraction_leaf': 0.0, 'rfc__classifier__n_estimators': 500, 'rfc__classifier__n_jobs': 1, 'rfc__classifier__oob_score': False, 'rfc__classifier__random_state': None, 'rfc__classifier__verbose': 0, 'rfc__classifier__warm_start': False, 'knn__steps': [('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=True)), ('classifier', KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='distance'))], 'knn__scaler1': StandardScaler(copy=True, with_mean=True, with_std=True), 'knn__pca': PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'knn__scaler2': StandardScaler(copy=True, with_mean=True, with_std=True), 'knn__classifier': KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=8, p=2,\n",
      "           weights='distance'), 'knn__scaler1__copy': True, 'knn__scaler1__with_mean': True, 'knn__scaler1__with_std': True, 'knn__pca__copy': True, 'knn__pca__iterated_power': 'auto', 'knn__pca__n_components': 5, 'knn__pca__random_state': None, 'knn__pca__svd_solver': 'auto', 'knn__pca__tol': 0.0, 'knn__pca__whiten': False, 'knn__scaler2__copy': True, 'knn__scaler2__with_mean': True, 'knn__scaler2__with_std': True, 'knn__classifier__algorithm': 'auto', 'knn__classifier__leaf_size': 30, 'knn__classifier__metric': 'minkowski', 'knn__classifier__metric_params': None, 'knn__classifier__n_jobs': 1, 'knn__classifier__n_neighbors': 8, 'knn__classifier__p': 2, 'knn__classifier__weights': 'distance', 'svc__steps': [('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False))], 'svc__scaler1': StandardScaler(copy=True, with_mean=True, with_std=True), 'svc__pca': PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
      "  svd_solver='auto', tol=0.0, whiten=False), 'svc__classifier': SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'svc__scaler1__copy': True, 'svc__scaler1__with_mean': True, 'svc__scaler1__with_std': True, 'svc__pca__copy': True, 'svc__pca__iterated_power': 'auto', 'svc__pca__n_components': 5, 'svc__pca__random_state': None, 'svc__pca__svd_solver': 'auto', 'svc__pca__tol': 0.0, 'svc__pca__whiten': False, 'svc__classifier__C': 10, 'svc__classifier__cache_size': 200, 'svc__classifier__class_weight': None, 'svc__classifier__coef0': 0.0, 'svc__classifier__decision_function_shape': None, 'svc__classifier__degree': 3, 'svc__classifier__gamma': 'auto', 'svc__classifier__kernel': 'rbf', 'svc__classifier__max_iter': -1, 'svc__classifier__probability': True, 'svc__classifier__random_state': None, 'svc__classifier__shrinking': True, 'svc__classifier__tol': 0.001, 'svc__classifier__verbose': False}\n"
     ]
    }
   ],
   "source": [
    "print(secondary_voting.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 16 ms, total: 2.9 s\n",
      "Wall time: 2.89 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time secondary_voting.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 1.01 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rfc', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=Tru...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]))],\n",
       "         n_jobs=1, voting='soft', weights=[0.5, 1, 1.5])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time secondary_voting.set_params(weights = [0.5, 1, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.85 s, sys: 20 ms, total: 2.87 s\n",
      "Wall time: 2.87 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99272384288890381"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time secondary_voting.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [07:49<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "runoff_election = []\n",
    "\n",
    "for weights in tqdm(secondary_weight_list):\n",
    "    secondary_voting.set_params(weights = weights)\n",
    "    runoff_election.append({'weights': weights,\n",
    "                            'train_score': secondary_voting.score(X_train, y_train),\n",
    "                            'test_score': secondary_voting.score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_score</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.842765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.5, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.842361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.75, 1.5, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.841956</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.25, 1.5, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.841350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.25, 1.25, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.840946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.5, 0.5, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.840946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.25, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.840946</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.25, 0.5, 0.75]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.840744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.75, 1.25, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.840340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.25, 0.75, 0.5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.840340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.5, 1.5, 0.5]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     test_score  train_score            weights\n",
       "68     0.842765          1.0    [1.0, 1.5, 0.5]\n",
       "43     0.842361          1.0   [0.75, 1.5, 0.5]\n",
       "92     0.841956          1.0   [1.25, 1.5, 0.5]\n",
       "88     0.841350          1.0  [1.25, 1.25, 0.5]\n",
       "98     0.840946          1.0   [1.5, 0.5, 0.75]\n",
       "63     0.840946          1.0   [1.0, 1.25, 0.5]\n",
       "74     0.840946          1.0  [1.25, 0.5, 0.75]\n",
       "38     0.840744          1.0  [0.75, 1.25, 0.5]\n",
       "78     0.840340          1.0  [1.25, 0.75, 0.5]\n",
       "117    0.840340          1.0    [1.5, 1.5, 0.5]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runoff_df = pd.DataFrame(runoff_election)\n",
    "runoff_df.sort_values('test_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "runoff_df.to_csv('data/election.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = VotingClassifier(estimators = [\n",
    "                                        ('rfc', rfc_pca_classifier), \n",
    "                                        ('knn', knn_pca_classifier), \n",
    "                                        ('svc', svc_pca_classifier)],\n",
    "                          voting = 'soft',\n",
    "                          weights = [1.0, 1.5, 0.5]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rfc', Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('scaler2', StandardScaler(copy=True, with_mean=True, with_std=Tru...  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))]))],\n",
       "         n_jobs=1, voting='soft', weights=[1.0, 1.5, 0.5])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_target = open('classifiers/final_model.p', 'wb')\n",
    "pickle.dump(final_model, pickle_target)\n",
    "pickle_target.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

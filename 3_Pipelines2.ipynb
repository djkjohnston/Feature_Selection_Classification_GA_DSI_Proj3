{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%run data_package_loading.py # Code loads data as well as packages that are relevant across most project phases\n",
    "%matplotlib inline\n",
    "\n",
    "uci_features = ['28',  '48',  '64', '105', '128', '153', '241', '281', '318', '336', \n",
    "                '338', '378', '433', '442', '451', '453', '455', '472', '475', '493']\n",
    "\n",
    "madelon_features = ['feat_257', 'feat_269', 'feat_308', 'feat_315', 'feat_336',\n",
    "                   'feat_341', 'feat_395', 'feat_504', 'feat_526', 'feat_639',\n",
    "                   'feat_681', 'feat_701', 'feat_724', 'feat_736', 'feat_769',\n",
    "                   'feat_808', 'feat_829', 'feat_867', 'feat_920', 'feat_956']\n",
    "\n",
    "Xuci_1 = Xuci_1[uci_features]\n",
    "Xuci_2 = Xuci_2[uci_features]\n",
    "Xuci_3 = Xuci_3[uci_features]\n",
    "\n",
    "# !conda install -y psycopg2\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, RFE, SelectFromModel, RFECV \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "Xdb_1 = pd.read_pickle('data/madelon_db_1')\n",
    "Xdb_2 = pd.read_pickle('data/madelon_db_2')\n",
    "Xdb_3 = pd.read_pickle('data/madelon_db_3')\n",
    "\n",
    "\n",
    "ydb_1 = Xdb_1['target']\n",
    "ydb_2 = Xdb_2['target']\n",
    "ydb_3 = Xdb_3['target']\n",
    "Xdb_1 = Xdb_1[madelon_features]\n",
    "Xdb_2 = Xdb_2[madelon_features]\n",
    "Xdb_3 = Xdb_3[madelon_features]\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_reduction(X, y, corr_thresh = 0.7):\n",
    "    \n",
    "    #find order of X features from least important to most important in predicting X\n",
    "    skb = SelectKBest(k=len(X.columns))\n",
    "    skb.fit(X, y)\n",
    "    \n",
    "    tmp_X = X[[col for p,col in sorted(zip(skb.pvalues_,X.columns))]]\n",
    "\n",
    "    # iterate through columns\n",
    "    for col in tmp_X.columns:\n",
    "        corrs = tmp_X.drop(col, axis=1).corrwith(tmp_X[col]) #store the correlations\n",
    "        \n",
    "        # if tested column is too highly correlated, drop it\n",
    "        if max(corrs) > corr_thresh:\n",
    "            tmp_X = tmp_X.drop(col, axis=1)\n",
    "            \n",
    "    return tmp_X, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                    ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "rfc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_pca_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC(probability=True))])\n",
    "\n",
    "# ada_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', AdaBoostClassifier())])\n",
    "\n",
    "# gbc_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "# xgb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('pca', PCA()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__n_neighbors': np.linspace(1,50).astype(int)}\n",
    "\n",
    "rfc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "             'classifier__n_estimators': [200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_pca_params = {'pca__n_components': [1, 3, 5],\n",
    "              'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "# ada_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0]}\n",
    "\n",
    "# gbc_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5],\n",
    "#              'classifier__loss': ['deviance', 'exponential'],\n",
    "#              'classifier__warm_start': [True, False]}\n",
    "\n",
    "# xgb_params = {'pca__n_components': [1, 3, 5],\n",
    "#               'classifier__n_estimators': [10, 50, 75, 100],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_gs(X, y, pipe, param):\n",
    "    \n",
    "    gs = GridSearchCV(pipe, param, cv=5, n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    \n",
    "    print('Best params:', gs.best_params_)\n",
    "    print('Best fitting score:', gs.best_score_)\n",
    "    print('Train score:', gs.score(X_train, y_train))\n",
    "    print('Test score:', gs.score(X_test, y_test))\n",
    "    \n",
    "    return gs.best_estimator_\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Xdb_1, ydb_1, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC\n",
      "Best params: {'classifier__C': 10, 'pca__n_components': 5}\n",
      "Best fitting score: 0.8270565249612613\n",
      "Train score: 0.879269689416\n",
      "Test score: 0.831447049313\n"
     ]
    }
   ],
   "source": [
    "# print(\"\\nDecision Tree\")\n",
    "# dtc_pca_classifier = test_train_gs(X_train, y_train, dtc_pca_pipe, dtc_pca_params)\n",
    "# print(\"\\nLogReg\")\n",
    "# lr_pca_classifier = test_train_gs(X_train, y_train, lr_pca_pipe, lr_pca_params)\n",
    "# print(\"\\nRandom Forest\")\n",
    "# rfc_pca_classifier = test_train_gs(X_train, y_train, rfc_pca_pipe, rfc_pca_params)\n",
    "# print(\"\\nKNN\")\n",
    "# knn_pca_classifier = test_train_gs(X_train, y_train, knn_pca_pipe, knn_pca_params)\n",
    "print(\"\\nSVC\")\n",
    "svc_pca_classifier = test_train_gs(X_train, y_train, svc_pca_pipe, svc_pca_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying SKB instead of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "rfc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('skb', SelectKBest()),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC())])\n",
    "\n",
    "# ada_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', AdaBoostClassifier())])\n",
    "\n",
    "# gbc_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', GradientBoostingClassifier())])\n",
    "\n",
    "# xgb_skb_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "#                      ('skb', SelectKBest()),\n",
    "#                      ('scaler2', StandardScaler()),\n",
    "#                      ('classifier', XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__n_neighbors': np.linspace(1,50).astype(int)}\n",
    "\n",
    "rfc_skb_params = {'skb__k': [5, 10, 15],\n",
    "             'classifier__n_estimators': [200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_skb_params = {'skb__k': [5, 10, 15],\n",
    "              'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "# ada_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0]}\n",
    "\n",
    "# gbc_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 25, 50, 75, 100, 200, 500],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5],\n",
    "#              'classifier__loss': ['deviance', 'exponential'],\n",
    "#              'classifier__warm_start': [True, False]}\n",
    "\n",
    "# xgb_skb_params = {'skb__k': [5, 10, 15],\n",
    "#               'classifier__n_estimators': [10, 50, 75, 100],\n",
    "#              'classifier__learning_rate': [0.1, .25, 0.5, 0.75, 1.0],\n",
    "#              'classifier__max_depth': [1, 2, 3, 4, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC\n",
      "Best params: {'classifier__C': 1000.0, 'skb__k': 15}\n",
      "Best fitting score: 0.8154685710435896\n",
      "Train score: 0.850434548272\n",
      "Test score: 0.820735650768\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision Tree\")\n",
    "dtc_skb_classifier = test_train_gs(X_train, y_train, dtc_skb_pipe, dtc_skb_params)\n",
    "print(\"\\nLogReg\")\n",
    "lr_skb_classifier = test_train_gs(X_train, y_train, lr_skb_pipe, lr_skb_params)\n",
    "print(\"\\nRandom Forest\")\n",
    "rfc_skb_classifier = test_train_gs(X_train, y_train, rfc_skb_pipe, rfc_skb_params)\n",
    "print(\"\\nKNN\")\n",
    "knn_skb_classifier = test_train_gs(X_train, y_train, knn_skb_pipe, knn_skb_params)\n",
    "print(\"\\nSVC\")\n",
    "svc_skb_classifier = test_train_gs(X_train, y_train, svc_skb_pipe, svc_skb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_pca_classifier = pickle.load(open('classifiers/rfc_classifier', 'rb'))\n",
    "# knn_pca_classifier = pickle.load(open('classifiers/knn_classifier', 'rb'))\n",
    "# svc_pca_classifier = pickle.load(open('classifiers/svc_classifier', 'rb'))\n",
    "# ada_pca_classifier = pickle.load(open('classifiers/ada_classifier', 'rb'))\n",
    "# gbc_pca_classifier = pickle.load(open('classifiers/gbc_classifier', 'rb'))\n",
    "\n",
    "# print(rfc_pca_classifier.score(X_test, y_test))\n",
    "# print(knn_pca_classifier.score(X_test, y_test))\n",
    "# print(svc_pca_classifier.score(X_test, y_test))\n",
    "# print(ada_pca_classifier.score(X_test, y_test))\n",
    "# print(gbc_pca_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_for_skb = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='log2', max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
    "            verbose=0, warm_start=False)\n",
    "\n",
    "dtc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                     ('scaler2', StandardScaler()),\n",
    "                     ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "lr_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                        ('scaler2', StandardScaler()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "knn_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                         ('scaler2', StandardScaler()),\n",
    "                     ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "rfc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                      ('scaler2', StandardScaler()),\n",
    "                     ('classifier', RandomForestClassifier())])\n",
    "\n",
    "svc_sfm_pipe = Pipeline([('scaler1', StandardScaler()),\n",
    "                     ('sfm', SelectFromModel(rfc_for_skb)),\n",
    "                         ('scaler2', StandardScaler()),\n",
    "                     ('classifier', SVC())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_sfm_params = {'classifier__max_depth': [1, 3, 5, 10, 15, None],\n",
    "             'classifier__splitter': ['random', 'best']}\n",
    "\n",
    "lr_sfm_params = {'classifier__penalty': ['l1', 'l2'],\n",
    "             'classifier__max_iter': [100, 500],\n",
    "             'classifier__C': np.logspace(-3,3,7)}\n",
    "\n",
    "knn_sfm_params = {'classifier__n_neighbors': np.linspace(1,50).astype(int)}\n",
    "\n",
    "rfc_sfm_params = {'classifier__n_estimators': [200, 500],\n",
    "              'classifier__max_features': ['log2', 'sqrt', 'auto'],\n",
    "              'classifier__oob_score': [True, False],\n",
    "             'classifier__max_depth': [1, 5, None]}\n",
    "\n",
    "svc_sfm_params = {'classifier__C': np.logspace(-3,3,7)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVC\n",
      "Best params: {'classifier__C': 1000.0}\n",
      "Best fitting score: 0.8160075456444115\n",
      "Train score: 0.849760830021\n",
      "Test score: 0.822352465643\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDecision Tree\")\n",
    "dtc_sfm_classifier = test_train_gs(X_train, y_train, dtc_sfm_pipe, dtc_sfm_params)\n",
    "print(\"\\nLogReg\")\n",
    "lr_sfm_classifier = test_train_gs(X_train, y_train, lr_sfm_pipe, lr_sfm_params)\n",
    "print(\"\\nRandom Forest\")\n",
    "rfc_sfm_classifier = test_train_gs(X_train, y_train, rfc_sfm_pipe, rfc_sfm_params)\n",
    "print(\"\\nKNN\")\n",
    "knn_sfm_classifier = test_train_gs(X_train, y_train, knn_sfm_pipe, knn_sfm_params)\n",
    "print(\"\\nSVC\")\n",
    "svc_sfm_classifier = test_train_gs(X_train, y_train, svc_sfm_pipe, svc_sfm_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's see all of the test scores again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Decision Tree: 0.751616814875\n",
      "LogReg: 0.601050929669\n",
      "Random Forest: 0.829830234438\n",
      "KNN: 0.833265966047\n",
      "SVC: 0.831447049313\n",
      "\n",
      "SelectKBest\n",
      "Decision Tree: 0.746564268391\n",
      "LogReg: 0.601455133387\n",
      "Random Forest: 0.825383993533\n",
      "KNN: 0.823767178658\n",
      "SVC: 0.820735650768\n",
      "\n",
      "SelectFromModel\n",
      "Decision Tree: 0.749797898141\n",
      "LogReg: 0.600848827809\n",
      "Random Forest: 0.828011317704\n",
      "KNN: 0.829021827001\n",
      "SVC: 0.822352465643\n"
     ]
    }
   ],
   "source": [
    "print(\"PCA\")\n",
    "print(\"Decision Tree:\", dtc_pca_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_pca_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_pca_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_pca_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_pca_classifier.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nSelectKBest\")\n",
    "print(\"Decision Tree:\", dtc_skb_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_skb_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_skb_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_skb_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_skb_classifier.score(X_test, y_test))\n",
    "\n",
    "print(\"\\nSelectFromModel\")\n",
    "print(\"Decision Tree:\", dtc_sfm_classifier.score(X_test, y_test))\n",
    "print(\"LogReg:\", lr_sfm_classifier.score(X_test, y_test))\n",
    "print(\"Random Forest:\", rfc_sfm_classifier.score(X_test, y_test))\n",
    "print(\"KNN:\", knn_sfm_classifier.score(X_test, y_test))\n",
    "print(\"SVC:\", svc_sfm_classifier.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try voting\n",
    "\n",
    "The PCA models consistently have the strongest accuracy scores. Let's try to see if we can increase the accuracy by ensembling all of the pipelines utilizing PCA. In addition to voting, let's use `GridSearchCV` to determine if weighting the votes will help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Pipeline.get_params of Pipeline(steps=[('scaler1', StandardScaler(copy=True, with_mean=True, with_std=True)), ('pca', PCA(copy=True, iterated_power='auto', n_components=5, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('classifier', SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_pca_classifier.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voting = VotingClassifier(estimators = [('dtc', dtc_pca_classifier), \n",
    "                                        ('lr', lr_pca_classifier),\n",
    "                                        ('rfc', rfc_pca_classifier), \n",
    "                                        ('knn', knn_pca_classifier), \n",
    "                                        ('svc', svc_pca_classifier)],\n",
    "                          voting = 'soft'\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = []\n",
    "\n",
    "for i in np.linspace(0.0001, 3, 7):\n",
    "    for j in np.linspace(0.0001, 3, 7):\n",
    "        for k in np.linspace(0.0001, 3, 7):\n",
    "            for l in np.linspace(0.0001, 3, 7):\n",
    "                for m in np.linspace(0.0001, 3, 7):\n",
    "                    weight_list.append([i, j, k, l, m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16807"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_params = {'weights': weight_list}\n",
    "\n",
    "voting_gs = GridSearchCV(voting, voting_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "voting_gs.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_gs.score(Xdb_2, ydb_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_gs.score(Xdb_3, ydb_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
